{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435381bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import time\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from build_model_ed import build_model_1, build_model_2, build_model_3\n",
    "from build_model_lstm import build_model_lstm_1, build_model_lstm_2, build_model_lstm_3\n",
    "from get_frames import get_frames\n",
    "from get_encoder_decoder import get_encoder_decoder\n",
    "from get_errors import get_ssim, get_mse, get_errors\n",
    "from assemble_image import assemble_image\n",
    "from load_models import load_encoder_decoder_model, load_lstm_model, load_models\n",
    "from prediction import predict_step, predict_image, plot_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7230ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu check\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data image list\n",
    "test_size = 0.1\n",
    "stride_step = 50\n",
    "norm_factor=1\n",
    "dtype = 'uint8'\n",
    "\n",
    "filename = f'save_data/e_d_test_all_str_50_ts_{test_size}_{dtype}_norm_{norm_factor}.pkl'\n",
    "#load data\n",
    "with open(filename, 'rb') as f:\n",
    "    image_list,frames_data = pickle.load(f)\n",
    "    \n",
    "del frames_data\n",
    "\n",
    "#image list\n",
    "print('Image list:')\n",
    "print('\\n'.join([f'{i}: {image}' for i, image in enumerate(image_list)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride_step_list = [50,100,160,200]\n",
    "unit_numb_list = [5,10,20,30]\n",
    "stateful_list = [False]\n",
    "sliding_window_settings_dict = {\n",
    "    stride_step_list[0]:[(6,1,0),(6,6,3)],\n",
    "    stride_step_list[1]:[(6,1,0),(6,6,3),(4,1,0),(4,4,2)],\n",
    "    stride_step_list[2]:[(6,1,0),(6,6,3),(4,1,0),(4,4,2)],\n",
    "    stride_step_list[3]:[(6,1,0),(6,6,3),(4,1,0),(4,4,2),(2,1,0),(2,2,1)],    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose image\n",
    "test_case = image_list[5]\n",
    "\n",
    "\n",
    "#get frames from the image\n",
    "path_list = ['PuckerImages//RGB_cropped',\n",
    "             'TwistImages//RGB',\n",
    "             'FoldImages//RGB',]\n",
    "\n",
    "print(f'Chosen image: {test_case}')\n",
    "for path in path_list:\n",
    "    if test_case[:4]==path[:4]:\n",
    "        break        \n",
    "img = Image.open(f'{path}//{test_case}')\n",
    "image_data_gt = np.array(img, dtype=dtype)\n",
    "#crop the end\n",
    "image_data_gt = image_data_gt[:,:-96,:]\n",
    "print(f'Image shape: {image_data_gt.shape}')\n",
    "plt.imshow(image_data_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e828e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load models\n",
    "stride_step = stride_step_list[0]\n",
    "window_size, window_size_predicted, overlap = sliding_window_settings_dict[stride_step][0]\n",
    "stateful = False\n",
    "repeat_prediction = 6\n",
    "frames_to_pred_total = 40\n",
    "verbose = 0\n",
    "print(f'Stride: {stride_step}; predict: {window_size, window_size_predicted, overlap}; repeat_prediction: {repeat_prediction}; stateful: {stateful}')\n",
    "\n",
    "predicted_data_dict = {}\n",
    "\n",
    "#get  ground truth frames\n",
    "image_data_frames_gt = get_frames(image_data_gt, stride_step, ifPrint = False)\n",
    "\n",
    "for unit_numb in unit_numb_list:\n",
    "    lstm_pars_dict = {\n",
    "        'stateful':stateful,\n",
    "        'window_size':window_size,\n",
    "        'window_size_predicted':window_size_predicted,\n",
    "        'overlap':overlap    \n",
    "    }\n",
    "\n",
    "    #load models\n",
    "    models_dict = load_models(unit_numb, stride_step, lstm_pars_dict)\n",
    "    \n",
    "    image_data_frames_list = predict_image(\n",
    "        image_data_frames_gt, \n",
    "        models_dict,\n",
    "        lstm_pars_dict, \n",
    "        repeat_prediction,\n",
    "        verbose=verbose,\n",
    "        frames_to_pred_total=frames_to_pred_total\n",
    "    )\n",
    "    \n",
    "    predicted_data_dict[unit_numb] = image_data_frames_list\n",
    "    \n",
    "plot_prediction(\n",
    "    image_data_frames_gt,\n",
    "    predicted_data_dict,\n",
    "    lstm_pars_dict,\n",
    "    repeat_prediction,\n",
    "    numb_cols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0155a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models\n",
    "stride_step = stride_step_list[0]\n",
    "window_size, window_size_predicted, overlap = sliding_window_settings_dict[stride_step][1]\n",
    "stateful = False\n",
    "repeat_prediction = 2\n",
    "frames_to_pred_total = 40\n",
    "verbose = 0\n",
    "print(f'Stride: {stride_step}; predict: {window_size, window_size_predicted, overlap}; repeat_prediction: {repeat_prediction}; stateful: {stateful}')\n",
    "\n",
    "\n",
    "predicted_data_dict = {}\n",
    "\n",
    "#get  ground truth frames\n",
    "image_data_frames_gt = get_frames(image_data_gt, stride_step, ifPrint = False)\n",
    "\n",
    "for unit_numb in unit_numb_list:\n",
    "    lstm_pars_dict = {\n",
    "        'stateful':stateful,\n",
    "        'window_size':window_size,\n",
    "        'window_size_predicted':window_size_predicted,\n",
    "        'overlap':overlap    \n",
    "    }\n",
    "\n",
    "    #load models\n",
    "    models_dict = load_models(unit_numb, stride_step, lstm_pars_dict)\n",
    "    \n",
    "    image_data_frames_list = predict_image(\n",
    "        image_data_frames_gt, \n",
    "        models_dict,\n",
    "        lstm_pars_dict, \n",
    "        repeat_prediction,\n",
    "        verbose=verbose,\n",
    "        frames_to_pred_total=frames_to_pred_total\n",
    "    )\n",
    "    \n",
    "    predicted_data_dict[unit_numb] = image_data_frames_list\n",
    "    \n",
    "plot_prediction(\n",
    "    image_data_frames_gt,\n",
    "    predicted_data_dict,\n",
    "    lstm_pars_dict,\n",
    "    repeat_prediction,\n",
    "    numb_cols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2aa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models\n",
    "stride_step = stride_step_list[1]\n",
    "window_size, window_size_predicted, overlap = sliding_window_settings_dict[stride_step][0]\n",
    "stateful = False\n",
    "repeat_prediction = 6\n",
    "frames_to_pred_total = 20\n",
    "verbose = 0\n",
    "print(f'Stride: {stride_step}; predict: {window_size, window_size_predicted, overlap}; repeat_prediction: {repeat_prediction}; stateful: {stateful}')\n",
    "\n",
    "predicted_data_dict = {}\n",
    "\n",
    "#get  ground truth frames\n",
    "image_data_frames_gt = get_frames(image_data_gt, stride_step, ifPrint = False)\n",
    "\n",
    "for unit_numb in unit_numb_list:\n",
    "    lstm_pars_dict = {\n",
    "        'stateful':stateful,\n",
    "        'window_size':window_size,\n",
    "        'window_size_predicted':window_size_predicted,\n",
    "        'overlap':overlap    \n",
    "    }\n",
    "\n",
    "    #load models\n",
    "    models_dict = load_models(unit_numb, stride_step, lstm_pars_dict)\n",
    "    \n",
    "    image_data_frames_list = predict_image(\n",
    "        image_data_frames_gt, \n",
    "        models_dict,\n",
    "        lstm_pars_dict, \n",
    "        repeat_prediction,\n",
    "        verbose=verbose,\n",
    "        frames_to_pred_total=frames_to_pred_total\n",
    "    )\n",
    "    \n",
    "    predicted_data_dict[unit_numb] = image_data_frames_list\n",
    "    \n",
    "plot_prediction(\n",
    "    image_data_frames_gt,\n",
    "    predicted_data_dict,\n",
    "    lstm_pars_dict,\n",
    "    repeat_prediction,\n",
    "    numb_cols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0720df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models\n",
    "stride_step = stride_step_list[1]\n",
    "window_size, window_size_predicted, overlap = sliding_window_settings_dict[stride_step][2]\n",
    "stateful = False\n",
    "repeat_prediction = 6\n",
    "frames_to_pred_total = 20\n",
    "verbose = 0\n",
    "print(f'Stride: {stride_step}; predict: {window_size, window_size_predicted, overlap}; repeat_prediction: {repeat_prediction}; stateful: {stateful}')\n",
    "\n",
    "predicted_data_dict = {}\n",
    "\n",
    "#get  ground truth frames\n",
    "image_data_frames_gt = get_frames(image_data_gt, stride_step, ifPrint = False)\n",
    "\n",
    "for unit_numb in unit_numb_list:\n",
    "    lstm_pars_dict = {\n",
    "        'stateful':stateful,\n",
    "        'window_size':window_size,\n",
    "        'window_size_predicted':window_size_predicted,\n",
    "        'overlap':overlap    \n",
    "    }\n",
    "\n",
    "    #load models\n",
    "    models_dict = load_models(unit_numb, stride_step, lstm_pars_dict)\n",
    "    \n",
    "    image_data_frames_list = predict_image(\n",
    "        image_data_frames_gt, \n",
    "        models_dict,\n",
    "        lstm_pars_dict, \n",
    "        repeat_prediction,\n",
    "        verbose=verbose,\n",
    "        frames_to_pred_total=frames_to_pred_total\n",
    "    )\n",
    "    \n",
    "    predicted_data_dict[unit_numb] = image_data_frames_list\n",
    "    \n",
    "plot_prediction(\n",
    "    image_data_frames_gt,\n",
    "    predicted_data_dict,\n",
    "    lstm_pars_dict,\n",
    "    repeat_prediction,\n",
    "    numb_cols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e0a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models\n",
    "stride_step = stride_step_list[1]\n",
    "window_size, window_size_predicted, overlap = sliding_window_settings_dict[stride_step][1]\n",
    "stateful = False\n",
    "repeat_prediction = 2\n",
    "frames_to_pred_total = 20\n",
    "verbose = 0\n",
    "print(f'Stride: {stride_step}; predict: {window_size, window_size_predicted, overlap}; repeat_prediction: {repeat_prediction}; stateful: {stateful}')\n",
    "\n",
    "predicted_data_dict = {}\n",
    "\n",
    "#get  ground truth frames\n",
    "image_data_frames_gt = get_frames(image_data_gt, stride_step, ifPrint = False)\n",
    "\n",
    "for unit_numb in unit_numb_list:\n",
    "    lstm_pars_dict = {\n",
    "        'stateful':stateful,\n",
    "        'window_size':window_size,\n",
    "        'window_size_predicted':window_size_predicted,\n",
    "        'overlap':overlap    \n",
    "    }\n",
    "\n",
    "    #load models\n",
    "    models_dict = load_models(unit_numb, stride_step, lstm_pars_dict)\n",
    "    \n",
    "    image_data_frames_list = predict_image(\n",
    "        image_data_frames_gt, \n",
    "        models_dict,\n",
    "        lstm_pars_dict, \n",
    "        repeat_prediction,\n",
    "        verbose=verbose,\n",
    "        frames_to_pred_total=frames_to_pred_total\n",
    "    )\n",
    "    \n",
    "    predicted_data_dict[unit_numb] = image_data_frames_list\n",
    "    \n",
    "plot_prediction(\n",
    "    image_data_frames_gt,\n",
    "    predicted_data_dict,\n",
    "    lstm_pars_dict,\n",
    "    repeat_prediction,\n",
    "    numb_cols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models\n",
    "stride_step = stride_step_list[1]\n",
    "window_size, window_size_predicted, overlap = sliding_window_settings_dict[stride_step][3]\n",
    "stateful = False\n",
    "repeat_prediction = 3\n",
    "frames_to_pred_total = 20\n",
    "verbose = 0\n",
    "print(f'Stride: {stride_step}; predict: {window_size, window_size_predicted, overlap}; repeat_prediction: {repeat_prediction}; stateful: {stateful}')\n",
    "\n",
    "predicted_data_dict = {}\n",
    "\n",
    "#get  ground truth frames\n",
    "image_data_frames_gt = get_frames(image_data_gt, stride_step, ifPrint = False)\n",
    "\n",
    "for unit_numb in unit_numb_list:\n",
    "    lstm_pars_dict = {\n",
    "        'stateful':stateful,\n",
    "        'window_size':window_size,\n",
    "        'window_size_predicted':window_size_predicted,\n",
    "        'overlap':overlap    \n",
    "    }\n",
    "\n",
    "    #load models\n",
    "    models_dict = load_models(unit_numb, stride_step, lstm_pars_dict)\n",
    "    \n",
    "    image_data_frames_list = predict_image(\n",
    "        image_data_frames_gt, \n",
    "        models_dict,\n",
    "        lstm_pars_dict, \n",
    "        repeat_prediction,\n",
    "        verbose=verbose,\n",
    "        frames_to_pred_total=frames_to_pred_total\n",
    "    )\n",
    "    \n",
    "    predicted_data_dict[unit_numb] = image_data_frames_list\n",
    "    \n",
    "plot_prediction(\n",
    "    image_data_frames_gt,\n",
    "    predicted_data_dict,\n",
    "    lstm_pars_dict,\n",
    "    repeat_prediction,\n",
    "    numb_cols=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a819a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d810bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df489683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c93ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
