{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312847b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d5bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc20c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from build_model_ed import build_model_1, build_model_2,build_model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb38ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "#gpu check\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b3cafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (19250, 2048, 160, 3)\n",
      "Training dataset dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "test_size = 0.1\n",
    "stride_step = 200\n",
    "norm_factor=1\n",
    "dtype = 'uint8'\n",
    "\n",
    "filename = f'save_data//e_d_train_all_str_{stride_step}_ts_{test_size}_{dtype}_norm_{norm_factor}.pkl'\n",
    "#filename = f'save_data//e_d_train_Puck_str_{stride_step}_ts_{test_size}_{dtype}_norm_{norm_factor}.pkl'\n",
    "#load train data\n",
    "with open(filename, 'rb') as f:\n",
    "    train_list,frames_data_train = pickle.load(f)\n",
    "    \n",
    "print(f'Training dataset shape: {frames_data_train.shape}')\n",
    "print(f'Training dataset dtype: {frames_data_train.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a000cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2048, 160, 3)]    0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 2048, 160, 3)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 2048, 160, 4)      112       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2048, 160, 4)     16        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1024, 160, 4)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 1024, 160, 8)      296       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024, 160, 8)     32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 512, 160, 8)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 512, 160, 16)      1168      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512, 160, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 256, 160, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 256, 160, 32)      4640      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256, 160, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 128, 160, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 128, 160, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128, 160, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 64, 80, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 80, 100)       57700     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64, 80, 100)      400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 40, 100)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 40, 120)       108120    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 40, 120)      480       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 20, 120)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 20, 140)       151340    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 20, 140)      560       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 8, 10, 140)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 11200)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                336030    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11200)             347200    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 10, 140)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 8, 10, 140)        176540    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 8, 10, 140)       560       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 16, 20, 140)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 20, 120)       151320    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 20, 120)      480       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 32, 40, 120)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 40, 100)       108100    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 32, 40, 100)      400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 64, 80, 100)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 64, 80, 64)        57664     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 64, 80, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 128, 160, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 128, 160, 32)      18464     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 128, 160, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 256, 160, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 256, 160, 16)      4624      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256, 160, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " up_sampling2d_5 (UpSampling  (None, 512, 160, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 512, 160, 8)       1160      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 512, 160, 8)      32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 1024, 160, 8)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 1024, 160, 4)      292       \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1024, 160, 4)     16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 2048, 160, 4)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 2048, 160, 3)      111       \n",
      "                                                                 \n",
      " rescaling_1 (Rescaling)     (None, 2048, 160, 3)      0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,547,249\n",
      "Trainable params: 1,545,313\n",
      "Non-trainable params: 1,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#training parameters\n",
    "epochs = 2000\n",
    "#for ps 2 and du 100\n",
    "batch_size = 3\n",
    "#for ps 4 and du 10\n",
    "batch_size = 8 \n",
    "#for ps 4 and du 5\n",
    "batch_size = 16\n",
    "#for model_ed_3\n",
    "batch_size = 8\n",
    "#for everything else\n",
    "batch_size = 16\n",
    "validation_split = 0.2\n",
    "\n",
    "dense_units_list = [100,60,40,20,10]\n",
    "dense_units_list = [10,20,40,60,100]\n",
    "dense_units_list=[5,10,20,40]\n",
    "dense_units_list=[10]\n",
    "\n",
    "\n",
    "for dense_units in dense_units_list:\n",
    "    ifBatchNorm = True\n",
    "    kernel_size = (3,3)\n",
    "    if 0:\n",
    "        nn_blocks_list = [\n",
    "            [\n",
    "                [[16,16], kernel_size, ifBatchNorm, (2,1)],\n",
    "                [[32,32], kernel_size, ifBatchNorm, (2,1)],\n",
    "                [[64, 64], kernel_size, ifBatchNorm, (2,1)],\n",
    "                [[128,128], kernel_size, ifBatchNorm, (2,1)], \n",
    "            ],  \n",
    "            [\n",
    "                [[16,16], kernel_size, ifBatchNorm, (4,1)],\n",
    "                [[32,32], kernel_size, ifBatchNorm, (4,1)],\n",
    "                [[64, 64], kernel_size, ifBatchNorm, (4,1)],\n",
    "                [[128,128], kernel_size, ifBatchNorm, (4,1)],            \n",
    "            ]                 \n",
    "        ]\n",
    "    else:\n",
    "        if 0:\n",
    "            nn_blocks_list = [\n",
    "                [\n",
    "                    [[16,16], kernel_size, ifBatchNorm, (4,1)],\n",
    "                    [[32,32], kernel_size, ifBatchNorm, (4,1)],\n",
    "                    [[64, 64], kernel_size, ifBatchNorm, (4,1)],\n",
    "                    [[128,128], kernel_size, ifBatchNorm, (4,1)],            \n",
    "                ],\n",
    "            ]\n",
    "        else:\n",
    "            if 1:\n",
    "                nn_blocks_list = [\n",
    "                    [\n",
    "                        [[4], kernel_size, ifBatchNorm, (2,1)],\n",
    "                        [[8], kernel_size, ifBatchNorm, (2,1)],\n",
    "                        [[16], kernel_size, ifBatchNorm, (2,1)],\n",
    "                        [[32], kernel_size, ifBatchNorm, (2,1)],  \n",
    "                        [[64], kernel_size, ifBatchNorm, (2,1)], \n",
    "                        [[100], kernel_size, ifBatchNorm, (2,2)], \n",
    "                        [[120], kernel_size, ifBatchNorm, (2,2)], \n",
    "                        [[140], kernel_size, ifBatchNorm, (2,2)], \n",
    "                    ],\n",
    "                ]\n",
    "            else:\n",
    "                nn_blocks_list = [\n",
    "                    [\n",
    "                        [[20], kernel_size, ifBatchNorm, (2,1)],\n",
    "                        [[40], kernel_size, ifBatchNorm, (2,1)],\n",
    "                        [[60], kernel_size, ifBatchNorm, (2,1)],\n",
    "                        [[80], kernel_size, ifBatchNorm, (2,1)],  \n",
    "                        [[100], kernel_size, ifBatchNorm, (2,1)], \n",
    "                        [[120], kernel_size, ifBatchNorm, (2,1)], \n",
    "                        [[140], kernel_size, ifBatchNorm, (2,1)], \n",
    "                        [[160], kernel_size, ifBatchNorm, (2,2)], \n",
    "                    ],\n",
    "                ]\n",
    "                \n",
    "                 \n",
    "        \n",
    "    \n",
    "    for nn_blocks in nn_blocks_list:\n",
    "        \n",
    "        #poolsize\n",
    "        ps = nn_blocks[0][-1][0]\n",
    "        \n",
    "        if (ps==4) and (dense_units==10 or dense_units==5):\n",
    "            continue\n",
    "        \n",
    "        model_name = f'model_ed_3_ps_{ps}_bn_{ifBatchNorm}_du_{dense_units}'\n",
    "\n",
    "        if 1:\n",
    "            #save data\n",
    "            save_data = [dense_units,ifBatchNorm,kernel_size,nn_blocks]\n",
    "            file_name = f'saved_models//stride_{stride_step}//{model_name}_settings.pkl'\n",
    "            with open(file_name, 'wb') as f:\n",
    "                pickle.dump(save_data, f)\n",
    "\n",
    "\n",
    "        input_shape = (2048, stride_step, 3)\n",
    "\n",
    "        loss = 'mean_squared_error'\n",
    "        optimizer = tf.keras.optimizers.Adadelta(learning_rate=0.1, name=\"Adadelta\")\n",
    "        #optimizer = tf.keras.optimizers.Adadelta(learning_rate=0.01, name=\"SGD\")\n",
    "\n",
    "\n",
    "        model = build_model_3(input_shape, dense_units, nn_blocks)\n",
    "\n",
    "        model.compile(loss=loss, \n",
    "                      optimizer=optimizer, )\n",
    "        model.summary() \n",
    "        \n",
    "        if 1:\n",
    "            #define callbacks\n",
    "            # Write TensorBoard logs\n",
    "            log_dir = f'./tensorboard/stride_{stride_step}/logs/{model_name}'\n",
    "            tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "            #Stop training when no improvement\n",
    "            early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
    "                                                              patience=10, \n",
    "                                                              restore_best_weights=True)\n",
    "            #Reduce learning rate when a metric has stopped improving\n",
    "            reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=5)\n",
    "            callbacks = [tensorboard, early_stopping, reduce_lr]\n",
    "        \n",
    "            model.fit(\n",
    "                x=frames_data_train,\n",
    "                y=frames_data_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_split=validation_split,\n",
    "                callbacks=callbacks,\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            model.save_weights(f'saved_models/stride_{stride_step}/{model_name}/{model_name}')\n",
    "            \n",
    "        del model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789afa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------------------------------\n",
    "InternalError                             Traceback (most recent call last)\n",
    "Input In [6], in <cell line: 19>()\n",
    "    107     reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=5)\n",
    "    108     callbacks = [tensorboard, early_stopping, reduce_lr]\n",
    "--> 110     model.fit(\n",
    "    111         x=frames_data_train,\n",
    "    112         y=frames_data_train,\n",
    "    113         batch_size=batch_size,\n",
    "    114         epochs=epochs,\n",
    "    115         validation_split=validation_split,\n",
    "    116         callbacks=callbacks,\n",
    "    117     )\n",
    "    121     model.save_weights(f'saved_models/{model_name}/{model_name}')\n",
    "    123 del model\n",
    "\n",
    "File ~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n",
    "     65 except Exception as e:  # pylint: disable=broad-except\n",
    "     66   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
    "---> 67   raise e.with_traceback(filtered_tb) from None\n",
    "     68 finally:\n",
    "     69   del filtered_tb\n",
    "\n",
    "File ~/.local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102, in convert_to_eager_tensor(value, ctx, dtype)\n",
    "    100     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n",
    "    101 ctx.ensure_initialized()\n",
    "--> 102 return ops.EagerTensor(value, ctx.device_name, dtype)\n",
    "\n",
    "InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac897e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01742de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea23153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard results\n",
    "\n",
    "#model_name = f'model_encoder_decoder_test_3'\n",
    "\n",
    "log_dir = f'./tensorboard/logs/{model_name}'\n",
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5ba3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
