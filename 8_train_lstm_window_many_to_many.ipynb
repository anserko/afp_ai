{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8ac718",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f1d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737b0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d53d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "from get_frames import get_frames\n",
    "from build_model_ed import build_model_1, build_model_2\n",
    "from build_model_lstm import build_model_lstm_1, build_model_lstm_2, build_model_lstm_3\n",
    "from create_encoder_decoder_data import process_image, process_dataset, get_full_path\n",
    "from get_encoder_decoder import get_encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12eff1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#gpu check\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aac6304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (770, 80, 5)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "unit_numb = 5\n",
    "test_size = 0.1\n",
    "stride_step = 50\n",
    "norm_factor=1\n",
    "dtype = 'uint8'\n",
    "file_name = f'save_data//encoded_model_2//encoded_{unit_numb}_{stride_step}_ts_{test_size}_{dtype}_norm_{norm_factor}.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    frames_data_encoded = pickle.load(f)\n",
    "    \n",
    "print(f'Data shape: {frames_data_encoded.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a871d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle\n",
    "np.random.shuffle(frames_data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817cf742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape: (770, 80, 5)\n",
      "Input data shape: (55440, 6, 5)\n",
      "Output data shape: (55440, 6, 5)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03e11d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 5)]         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 20)          2080      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 20)          3280      \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 5)           105       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5465 (21.35 KB)\n",
      "Trainable params: 5465 (21.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cells_list = [20,20]\n",
    "ifDense = True\n",
    "input_shape = (None, unit_numb)\n",
    "many_to_many = True\n",
    "loss = 'mean_squared_error'\n",
    "learning_rate = 0.1\n",
    "optimizer_name = \"Adadelta\"\n",
    "optimizer = tf.keras.optimizers.legacy.Adadelta(learning_rate=learning_rate, name=optimizer_name)\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "model = build_model_lstm_3(input_shape, cells_list, ifDense=ifDense, ifDropout=False, many_to_many=many_to_many)\n",
    "#model.stateful = True\n",
    "model.compile(loss=loss, \n",
    "              optimizer=optimizer, )\n",
    "              #metrics=metrics)\n",
    "    \n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0027e1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7e49ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function keras.src.activations.tanh(x)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check activation function of the lstm layer\n",
    "model.layers[1].activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "851991b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training 16 ifDense False bp \n",
    "\n",
    "folder = 'lstm_window_many_to_many'\n",
    "epochs = 2000\n",
    "batch_size = 72\n",
    "validation_split = 0.1\n",
    "\n",
    "cells_list_str = '_'.join(str(x) for x in cells_list)\n",
    "\n",
    "model_name = f'model_lstm_window_{window_size_predicted}_units_{unit_numb}_bs2_{input_shape[-1]}_{cells_list_str}_ifDense_{ifDense}'\n",
    "model_name = f'model_lstm_window_{window_size_predicted}_overlap_{overlap}_units_{unit_numb}_bs2_{input_shape[-1]}_{cells_list_str}_ifDense_{ifDense}'\n",
    "\n",
    "\n",
    "#define callbacks\n",
    "# Write TensorBoard logs\n",
    "log_dir = f'./tensorboard/{folder}/logs/{model_name}'\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "#Stop training when no improvement\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
    "                                                  patience=6, \n",
    "                                                  restore_best_weights=True)\n",
    "#Reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=3)\n",
    "callbacks = [tensorboard, early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aedc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "if 1:\n",
    "    ld = log_dir\n",
    "else:\n",
    "    ld=None\n",
    "!rm -rf $ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13a28218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4990/4990 [==============================] - 16s 3ms/step - loss: 0.0366 - val_loss: 0.0339 - lr: 0.1000\n",
      "Epoch 2/2000\n",
      "4990/4990 [==============================] - 13s 3ms/step - loss: 0.0267 - val_loss: 0.0222 - lr: 0.1000\n",
      "Epoch 3/2000\n",
      "4990/4990 [==============================] - 15s 3ms/step - loss: 0.0183 - val_loss: 0.0167 - lr: 0.1000\n",
      "Epoch 4/2000\n",
      "4990/4990 [==============================] - 14s 3ms/step - loss: 0.0140 - val_loss: 0.0127 - lr: 0.1000\n",
      "Epoch 5/2000\n",
      "4990/4990 [==============================] - 14s 3ms/step - loss: 0.0115 - val_loss: 0.0112 - lr: 0.1000\n",
      "Epoch 6/2000\n",
      "4990/4990 [==============================] - 14s 3ms/step - loss: 0.0103 - val_loss: 0.0099 - lr: 0.1000\n",
      "Epoch 7/2000\n",
      "4990/4990 [==============================] - 13s 3ms/step - loss: 0.0089 - val_loss: 0.0083 - lr: 0.1000\n",
      "Epoch 8/2000\n",
      "4990/4990 [==============================] - 13s 3ms/step - loss: 0.0073 - val_loss: 0.0067 - lr: 0.1000\n",
      "Epoch 9/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0060 - val_loss: 0.0056 - lr: 0.1000\n",
      "Epoch 10/2000\n",
      "4990/4990 [==============================] - 13s 3ms/step - loss: 0.0051 - val_loss: 0.0049 - lr: 0.1000\n",
      "Epoch 11/2000\n",
      "4990/4990 [==============================] - 13s 3ms/step - loss: 0.0045 - val_loss: 0.0043 - lr: 0.1000\n",
      "Epoch 12/2000\n",
      "4990/4990 [==============================] - 14s 3ms/step - loss: 0.0040 - val_loss: 0.0039 - lr: 0.1000\n",
      "Epoch 13/2000\n",
      "4990/4990 [==============================] - 14s 3ms/step - loss: 0.0037 - val_loss: 0.0036 - lr: 0.1000\n",
      "Epoch 14/2000\n",
      "4990/4990 [==============================] - 14s 3ms/step - loss: 0.0034 - val_loss: 0.0033 - lr: 0.1000\n",
      "Epoch 15/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0032 - val_loss: 0.0032 - lr: 0.1000\n",
      "Epoch 16/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0030 - val_loss: 0.0030 - lr: 0.1000\n",
      "Epoch 17/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0029 - val_loss: 0.0029 - lr: 0.1000\n",
      "Epoch 18/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0028 - val_loss: 0.0028 - lr: 0.1000\n",
      "Epoch 19/2000\n",
      "4990/4990 [==============================] - 13s 3ms/step - loss: 0.0027 - val_loss: 0.0027 - lr: 0.1000\n",
      "Epoch 20/2000\n",
      "4990/4990 [==============================] - 13s 3ms/step - loss: 0.0026 - val_loss: 0.0026 - lr: 0.1000\n",
      "Epoch 21/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0026 - val_loss: 0.0026 - lr: 0.1000\n",
      "Epoch 22/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0025 - val_loss: 0.0025 - lr: 0.1000\n",
      "Epoch 23/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0025 - val_loss: 0.0025 - lr: 0.1000\n",
      "Epoch 24/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0024 - val_loss: 0.0024 - lr: 0.1000\n",
      "Epoch 25/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0024 - val_loss: 0.0024 - lr: 0.1000\n",
      "Epoch 26/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0024 - val_loss: 0.0024 - lr: 0.1000\n",
      "Epoch 27/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0024 - lr: 0.1000\n",
      "Epoch 28/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.1000\n",
      "Epoch 29/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.0100\n",
      "Epoch 30/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.0100\n",
      "Epoch 31/2000\n",
      "4990/4990 [==============================] - 13s 3ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 0.0100\n",
      "Epoch 32/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-03\n",
      "Epoch 33/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-03\n",
      "Epoch 34/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-03\n",
      "Epoch 35/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-04\n",
      "Epoch 36/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-04\n",
      "Epoch 37/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-04\n",
      "Epoch 38/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-05\n",
      "Epoch 39/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-05\n",
      "Epoch 40/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-05\n",
      "Epoch 41/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-06\n",
      "Epoch 42/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-06\n",
      "Epoch 43/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-06\n",
      "Epoch 44/2000\n",
      "4990/4990 [==============================] - 12s 2ms/step - loss: 0.0023 - val_loss: 0.0023 - lr: 1.0000e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7dd2c9f0c990>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bs 10 [10,10]\n",
    "model.fit(\n",
    "    x_train_lstm,\n",
    "    y_train_lstm,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=validation_split,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4227e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f'saved_models/{folder}/{model_name}/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d93d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af24b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8bc00f4d08a0dd16\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8bc00f4d08a0dd16\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tensorboard results\n",
    "folder = 'lstm_window'\n",
    "cells_list = [10,10,10]\n",
    "cells_list_str = '_'.join(str(x) for x in cells_list)\n",
    "\n",
    "\n",
    "model_name = f'model_lstm_window_units_{unit_numb}_bs2_{input_shape[-1]}_{cells_list_str}_ifDense_{ifDense}'\n",
    "\n",
    "log_dir = f'./tensorboard/{folder}/logs/{model_name}'\n",
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ae1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
